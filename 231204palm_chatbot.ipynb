{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f96a4b-d640-4239-9681-815a56ff4472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 04:29:16.104276: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 04:29:17.331987: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-12-04 04:29:17.332122: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-12-04 04:29:17.332133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there, how can I help you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what's your name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Bard, and I'm an AI assistant that can help you with a variety of tasks.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Tell me where is the best place for trip?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are many great places to travel, depending on your interests and budget. Some popular destinations include Paris, Rome, New York City, and London.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Tell me some movies about Paris.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are many great movies about Paris, including \"Am√©lie\", \"Before Sunset\", \"Midnight in Paris\", and \"The City of Lost Children\".\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Then Recommend me some trip schedule about movies about Paris.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a possible itinerary for a trip to Paris based on the movies you mentioned:\n",
      "\n",
      "* Day 1: Arrive in Paris and check into your hotel. In the evening, watch \"Am√©lie\".\n",
      "* Day 2: Visit the Eiffel Tower, the Louvre Museum, and the Champs-√âlys√©es. In the evening, watch \"Before Sunset\".\n",
      "* Day 3: Take a walk through the Tuileries Gardens, visit the Palace of Versailles, and have dinner at a traditional French restaurant. In the evening, watch \"Midnight in Paris\".\n",
      "* Day 4: Visit the Sacr√©-C≈ìur Basilica, the Latin Quarter, and the Jardin du Luxembourg. In the evening, watch \"The City of Lost Children\".\n",
      "\n",
      "This is just a suggested itinerary, of course, and you can customize it to fit your interests and budget.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " thks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're welcome!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Recommend me some trip schedules about movies in Paris.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are some possible trip schedules for movies in Paris:\n",
      "\n",
      "* Day 1: Arrive in Paris and check into your hotel. In the evening, watch \"Am√©lie\" at the Grand Rex.\n",
      "* Day 2: Visit the Eiffel Tower, the Louvre Museum, and the Champs-√âlys√©es. In the evening, watch \"Before Sunset\" at the Cin√©math√®que Fran√ßaise.\n",
      "* Day 3: Take a walk through the Tuileries Gardens, visit the Palace of Versailles, and have dinner at a traditional French restaurant. In the evening, watch \"Midnight in Paris\" at the Cinema Jean Vigo.\n",
      "* Day 4: Visit the Sacr√©-C≈ìur Basilica, the Latin Quarter, and the Jardin du Luxembourg. In the evening, watch \"The City of Lost Children\" at the Cin√©math√®que Fran√ßaise.\n",
      "\n",
      "This is just a suggested itinerary, of course, and you can customize it to fit your interests and budget.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " What's the difference between Bard and PaLM?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bard and PaLM are both large language models that were trained on massive datasets of text and code. However, there are some key differences between the two models.\n",
      "\n",
      "* Bard was trained on a dataset of text and code, while PaLM was trained on a dataset of text, code, and images. This gives PaLM a wider range of knowledge and abilities than Bard.\n",
      "* Bard was trained using a technique called \"fine-tuning\", while PaLM was trained using a technique called \"self-supervised learning\". Fine-tuning involves training a model on a specific task, while self-supervised learning involves training a model on a task that does not require human supervision. This gives PaLM a more general knowledge base than Bard.\n",
      "* Bard is a commercial product, while PaLM is a research project. This means that Bard is subject to certain restrictions, such as not being able to generate text that is sexually explicit or violent. PaLM does not have these restrictions, and can generate text on any topic.\n",
      "\n",
      "Overall, PaLM is a more powerful and versatile language model than Bard. However, Bard is still a very capable language model, and it is likely to continue to improve in the future.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Í≥†ÎßàÏõå\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're welcome!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " There's a llama in my garden üò± What should I do?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are generally docile animals, but they can be dangerous if they feel threatened. If you see a llama in your garden, it is best to stay calm and avoid making any sudden movements. You can try to shoo the llama away by making loud noises or waving your arms. If the llama does not leave, you can call animal control for assistance.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " exit\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.language_models import ChatModel\n",
    "\n",
    "PROJECT_ID = \"sessac-project-13\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "chat_model = ChatModel.from_pretrained(\"chat-bison@001\")\n",
    "\n",
    "parameters = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_output_tokens\": 256,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "}\n",
    "\n",
    "chat = chat_model.start_chat()\n",
    "\n",
    "while True:\n",
    "    message = input()\n",
    "    if message == 'exit':\n",
    "        break\n",
    "    response = chat.send_message(message, **parameters)\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0913755-db9e-4d6d-9447-f1b52f410f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
